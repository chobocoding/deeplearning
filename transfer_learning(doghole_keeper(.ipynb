{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "hw5_201711001.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chobocoding/deeplearning/blob/main/doghole_keeper(transfer%20learning).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "taqFvpC_QXNN"
      },
      "source": [
        "# !apt install unzip\n",
        "# !unzip hw5_doghole_keeper.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pcNBIE77vlVM",
        "outputId": "f60faece-a29b-450a-c178-5d59ba5941f7"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "import os\n",
        "os.chdir('/content/drive/MyDrive/Colab Notebooks/IT융합/hw5')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "30EAMEIuSo98"
      },
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "import glob\n",
        "from PIL import Image\n",
        "import random\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "from torchvision import transforms as T\n",
        "import torchvision.models as models"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wsGRRAw8XMwh"
      },
      "source": [
        "### 1. Data preparation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8R2_D4_YTfYj"
      },
      "source": [
        "transform = T.Compose([T.Resize(256), T.RandomCrop(224), T.ToTensor()])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bJbia-qIT-94"
      },
      "source": [
        "class Dataset(Dataset):\n",
        "    def __init__(self, path='train'):\n",
        "        super(Dataset, self).__init__()\n",
        "\n",
        "        self.img_path = []\n",
        "        bo_path = glob.glob(path+'/bo/*.jpg')\n",
        "        notbo_path = glob.glob(path+'/not_bo/*.jpg')\n",
        "        self.img_path = bo_path + notbo_path\n",
        "\n",
        "        self.label_list = [1]*len(bo_path) + [0]*len(notbo_path)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        img = cv2.imread(self.img_path[index])\n",
        "        img_pil = Image.fromarray(img)\n",
        "        self.img_tensor = transform(img_pil)\n",
        "        self.label_tensor = torch.tensor(self.label_list[index])\n",
        "        return self.img_tensor.to('cuda:0'), self.label_tensor.to('cuda:0')\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.img_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6HNEkE6eWme6"
      },
      "source": [
        "training_dataset = Dataset('train')\n",
        "training_loader = DataLoader(dataset=training_dataset, batch_size=8, shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EW8qUm_eW-1V"
      },
      "source": [
        "validation_dataset = Dataset('valid')\n",
        "validation_loader = DataLoader(dataset=validation_dataset, batch_size=8, shuffle=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NwKUKK6NXqtD"
      },
      "source": [
        "### 2. Constructing a convolutional neural network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8GlXRRLfXE-a"
      },
      "source": [
        "vgg16 = models.vgg16(pretrained=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HWiSQWbS_ygq",
        "outputId": "4b6f88db-df96-48a1-bdcf-b46d562196af"
      },
      "source": [
        "vgg16"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "VGG(\n",
              "  (features): Sequential(\n",
              "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): ReLU(inplace=True)\n",
              "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (3): ReLU(inplace=True)\n",
              "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (6): ReLU(inplace=True)\n",
              "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (8): ReLU(inplace=True)\n",
              "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (11): ReLU(inplace=True)\n",
              "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (13): ReLU(inplace=True)\n",
              "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (15): ReLU(inplace=True)\n",
              "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (18): ReLU(inplace=True)\n",
              "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (20): ReLU(inplace=True)\n",
              "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (22): ReLU(inplace=True)\n",
              "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (25): ReLU(inplace=True)\n",
              "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (27): ReLU(inplace=True)\n",
              "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (29): ReLU(inplace=True)\n",
              "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
              "  (classifier): Sequential(\n",
              "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
              "    (1): ReLU(inplace=True)\n",
              "    (2): Dropout(p=0.5, inplace=False)\n",
              "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
              "    (4): ReLU(inplace=True)\n",
              "    (5): Dropout(p=0.5, inplace=False)\n",
              "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iX6oWu9u4hbd",
        "outputId": "fe23afaf-1dde-425d-f62f-efdf7cd0000d"
      },
      "source": [
        "vgg16.classifier[0].in_features"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "25088"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QLkqv96be1CB"
      },
      "source": [
        "# freeze\n",
        "for param in vgg16.parameters():\n",
        "    param.requires_grad = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l90y8i4yYbQa"
      },
      "source": [
        "num_features = vgg16.classifier[6].in_features\n",
        "vgg16.classifier[6] = nn.Sequential(\n",
        "    nn.Linear(num_features, 2)\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ypOMD0nY5Zz"
      },
      "source": [
        "vgg16 = vgg16.to('cuda:0')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q3eYc1EXZN3J"
      },
      "source": [
        "### 3. Loss function and optimization method"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sRPzR0cZZGR0"
      },
      "source": [
        "loss_function = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(vgg16.parameters(), lr=0.0005)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b_FZkxxhZlIR"
      },
      "source": [
        "### 4. Training of a neural network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qB9jUG6SJNNA"
      },
      "source": [
        "def val_acc():\n",
        "    pred_list = []\n",
        "    label_list = []\n",
        "\n",
        "    for itr, data in enumerate(validation_loader):\n",
        "        inputs, labels = data\n",
        "\n",
        "        pred = vgg16(inputs)\n",
        "        pred_category = torch.argmax(pred, dim=1)\n",
        "\n",
        "        pred_list = pred_list + list(pred_category)\n",
        "        label_list = label_list + list(labels)\n",
        "\n",
        "    accu = np.mean( np.array(pred_list) == np.array(label_list) )\n",
        "    print(\"     Validation accuracy:\", accu)\n",
        "    return None"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XBVoeinNZnuI",
        "outputId": "c789d059-afe2-4449-c5ad-c86097ed7442"
      },
      "source": [
        "for epoch in range(6):\n",
        "    loss_val = 0\n",
        "    for itr, data in enumerate(training_loader):\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        inputs, labels = data\n",
        "\n",
        "        pred = vgg16(inputs)\n",
        "        loss = loss_function(pred, labels)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        loss_val += loss.item()\n",
        "\n",
        "    print(\"Epoch:\", epoch+1, \"  , Loss:\", loss_val)\n",
        "    if (epoch+1) % 2 == 0: val_acc()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1   , Loss: 4.647249927744269\n",
            "Epoch: 2   , Loss: 1.1398980850353837\n",
            "     Validation accuracy: 0.9666666666666667\n",
            "Epoch: 3   , Loss: 0.734001649543643\n",
            "Epoch: 4   , Loss: 0.3361550129484385\n",
            "     Validation accuracy: 0.9666666666666667\n",
            "Epoch: 5   , Loss: 0.24052892869804054\n",
            "Epoch: 6   , Loss: 0.41657176171429455\n",
            "     Validation accuracy: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NC7K-o4AbQ3Z"
      },
      "source": [
        "### 5. Prediction and evluation for the validation set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4g3F92fvaSlZ",
        "outputId": "9b1a8d32-5dcd-40c4-b038-565c7e9f9cae"
      },
      "source": [
        "pred_list = []\n",
        "label_list = []\n",
        "for itr, data in enumerate(validation_loader):\n",
        "    inputs, labels = data\n",
        "    pred = vgg16(inputs)\n",
        "    pred_category = torch.argmax(pred, dim=1)\n",
        "    pred_list = pred_list + list(pred_category)\n",
        "    label_list = label_list + list(labels)\n",
        "accu = np.mean( np.array(pred_list) == np.array(label_list) )\n",
        "print(\"Validation accuracy:\", accu)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation accuracy: 0.9333333333333333\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CKqpi4p7cHpB",
        "outputId": "e801512d-64e1-4054-a3fc-df85900d305e"
      },
      "source": [
        "pred_list"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[tensor(1, device='cuda:0'),\n",
              " tensor(1, device='cuda:0'),\n",
              " tensor(1, device='cuda:0'),\n",
              " tensor(1, device='cuda:0'),\n",
              " tensor(0, device='cuda:0'),\n",
              " tensor(1, device='cuda:0'),\n",
              " tensor(1, device='cuda:0'),\n",
              " tensor(0, device='cuda:0'),\n",
              " tensor(1, device='cuda:0'),\n",
              " tensor(1, device='cuda:0'),\n",
              " tensor(0, device='cuda:0'),\n",
              " tensor(0, device='cuda:0'),\n",
              " tensor(0, device='cuda:0'),\n",
              " tensor(0, device='cuda:0'),\n",
              " tensor(0, device='cuda:0'),\n",
              " tensor(0, device='cuda:0'),\n",
              " tensor(0, device='cuda:0'),\n",
              " tensor(0, device='cuda:0'),\n",
              " tensor(0, device='cuda:0'),\n",
              " tensor(0, device='cuda:0'),\n",
              " tensor(0, device='cuda:0'),\n",
              " tensor(0, device='cuda:0'),\n",
              " tensor(0, device='cuda:0'),\n",
              " tensor(0, device='cuda:0'),\n",
              " tensor(0, device='cuda:0'),\n",
              " tensor(0, device='cuda:0'),\n",
              " tensor(0, device='cuda:0'),\n",
              " tensor(0, device='cuda:0'),\n",
              " tensor(0, device='cuda:0'),\n",
              " tensor(0, device='cuda:0')]"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o7U1263if9VE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "39166e96-e5d1-4f38-e1f0-619c9d754d3d"
      },
      "source": [
        "pred_list"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[tensor(1, device='cuda:0'),\n",
              " tensor(1, device='cuda:0'),\n",
              " tensor(1, device='cuda:0'),\n",
              " tensor(1, device='cuda:0'),\n",
              " tensor(1, device='cuda:0'),\n",
              " tensor(1, device='cuda:0'),\n",
              " tensor(1, device='cuda:0'),\n",
              " tensor(1, device='cuda:0'),\n",
              " tensor(1, device='cuda:0'),\n",
              " tensor(1, device='cuda:0'),\n",
              " tensor(0, device='cuda:0'),\n",
              " tensor(0, device='cuda:0'),\n",
              " tensor(0, device='cuda:0'),\n",
              " tensor(0, device='cuda:0'),\n",
              " tensor(0, device='cuda:0'),\n",
              " tensor(0, device='cuda:0'),\n",
              " tensor(0, device='cuda:0'),\n",
              " tensor(0, device='cuda:0'),\n",
              " tensor(0, device='cuda:0'),\n",
              " tensor(0, device='cuda:0'),\n",
              " tensor(0, device='cuda:0'),\n",
              " tensor(0, device='cuda:0'),\n",
              " tensor(0, device='cuda:0'),\n",
              " tensor(0, device='cuda:0'),\n",
              " tensor(0, device='cuda:0'),\n",
              " tensor(0, device='cuda:0'),\n",
              " tensor(0, device='cuda:0'),\n",
              " tensor(0, device='cuda:0'),\n",
              " tensor(0, device='cuda:0'),\n",
              " tensor(0, device='cuda:0')]"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ww37wnjsyzLf"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
